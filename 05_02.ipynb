{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning Swin Transformer on CIFAR10\n",
    "## Chapter 5 Module 2\n",
    "\n",
    "## Setup and Imports\n",
    "We begin by installing essential libraries such as Hugging Face Transformers, Datasets, Torchvision, and Accelerate. These provide utilities for model loading, data handling, and efficient training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U transformers datasets torchvision evaluate accelerate --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing CIFAR-10 with a Swin-Compatible Pipeline\n",
    "We define a transform that resizes CIFAR-10 images to 224x224 (required by Swin) and initializes a Hugging Face image processor to match the pretrained Swin model’s expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dangural/anaconda3/envs/tcv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoImageProcessor, SwinForImageClassification, Trainer, TrainingArguments\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing CIFAR-10 with a Swin-Compatible Pipeline\n",
    "We define a transform that resizes CIFAR-10 images to 224x224 (required by Swin) and initializes a Hugging Face image processor to match the pretrained Swin model’s expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"microsoft/swin-tiny-patch4-window7-224\"\n",
    "processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=processor.image_mean, std=processor.image_std),\n",
    "])\n",
    "\n",
    "train_dataset = CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "test_dataset = CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "# Wrap for Hugging Face Trainer\n",
    "class CIFAR10_HFDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.dataset[idx]\n",
    "        return {\"pixel_values\": image, \"label\": label}\n",
    "\n",
    "hf_train = CIFAR10_HFDataset(train_dataset)\n",
    "hf_test = CIFAR10_HFDataset(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Pretrained Swin Transformer\n",
    "We load the Swin-Tiny model from Hugging Face's model hub, specifying num_labels=10 to match CIFAR-10’s classes. The ignore_mismatched_sizes=True argument ensures compatibility even if the classification head dimensions differ.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SwinForImageClassification were not initialized from the model checkpoint at microsoft/swin-tiny-patch4-window7-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([10]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([10, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = SwinForImageClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=10,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "# Freeze everything except the classification head\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Evaluation Metrics\n",
    "This function calculates evaluation metrics (currently just accuracy) from the model's predictions. It will be used by the Trainer during evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    acc = (preds == labels).mean()\n",
    "    return {\"accuracy\": acc}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Transfer Learning TrainingArguments\n",
    "Here we define hyperparameters for the transfer learning phase, such as batch size, evaluation strategy, and output directory. This setup uses the Hugging Face TrainingArguments API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./swin-cifar10-transfer\",\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=5e-4,\n",
    "    logging_dir='./logs',\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=hf_train,\n",
    "    eval_dataset=hf_test,\n",
    "    tokenizer=processor,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning the Entire Swin Model\n",
    "Now we unfreeze all model parameters and define a new training configuration for full fine-tuning. This assumes the previous stage may have trained only the classification head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gr/3k2bjlzn7js5c6j_zqrbnlvm0000gn/T/ipykernel_21577/229771633.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/Users/dangural/anaconda3/envs/tcv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4689' max='4689' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4689/4689 27:56, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.208600</td>\n",
       "      <td>0.117522</td>\n",
       "      <td>0.962100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.056100</td>\n",
       "      <td>0.106177</td>\n",
       "      <td>0.972300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>0.108439</td>\n",
       "      <td>0.977400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dangural/anaconda3/envs/tcv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/dangural/anaconda3/envs/tcv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4689, training_loss=0.09301996749711967, metrics={'train_runtime': 1682.2373, 'train_samples_per_second': 89.167, 'train_steps_per_second': 2.787, 'total_flos': 3.7292317913088e+18, 'train_loss': 0.09301996749711967, 'epoch': 3.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "finetune_args = TrainingArguments(\n",
    "    output_dir=\"./swin-cifar10-finetuned\",\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=1e-5,  # Lower learning rate for fine-tuning\n",
    "    logging_dir='./logs',\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "finetune_trainer = Trainer(\n",
    "    model=model,\n",
    "    args=finetune_args,\n",
    "    train_dataset=hf_train,\n",
    "    eval_dataset=hf_test,\n",
    "    tokenizer=processor,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "finetune_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Evaluation on the Fine-Tuned Model\n",
    "Finally, we evaluate the fully fine-tuned Swin model on the CIFAR-10 test set using the Trainer’s evaluate() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_trainer.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
