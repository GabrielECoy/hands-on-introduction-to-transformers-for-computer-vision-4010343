{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing CNN to Transformer\n",
    "## Chapter 2 Module 4\n",
    "\n",
    "In our first code example, we are going to install some key libraries that we will need for our code practices later. We will also do a very basic comparision of the two famous models, AlexNet vs ViT!\n",
    "\n",
    "## Installation\n",
    "Before we can get started, pip install the libraries below. `torch` `torchvision` `transformers` `pillow` will all help with our model inference. `fiftyone` is an open source library to help manage computer vision datasets as well as evaluation, visualization, and more that we will leverage for our examples. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch torchvision transformers pillow  fiftyone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a Subset of Imagenet\n",
    "\n",
    "The first part of FiftyOne we will leverage is the dataset zoo. Instead of manually collecting all 1TB of [ImageNet](https://www.image-net.org/index.php), we will use a subset from the [FiftyOne Dataset Zoo](https://docs.voxel51.com/dataset_zoo/index.html) called [ImageNet-Sample](https://docs.voxel51.com/dataset_zoo/datasets.html#imagenet-sample). The sample contains 1,000 images but we will load in just 50 for our example.\n",
    "\n",
    "After the dataset is loaded, we launch the [FiftyOne App](https://docs.voxel51.com/user_guide/app.html) to visualize our dataset. You can view the app in your notebook below the cell. If you are running locally, you can also launch the notebook in your browser with `localhost:5151`. Try exploring ImageNet for yourself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz \n",
    "\n",
    "dataset = foz.load_zoo_dataset(\n",
    "    \"imagenet-sample\",\n",
    "    dataset_name=\"Imagenet-Sample\",\n",
    "    max_samples=50,\n",
    "    shuffle=True,\n",
    "    overwrite=True,\n",
    ")\n",
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![imagenet](./assets/imagenet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try filtering your dataset on its labels by using the sidebar! You can select any of the classes in your dataset to see those samples!\n",
    "\n",
    "![labels](./assets/labels.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Showdown\n",
    "\n",
    "Now that we have our dataset loaded and ready to go, its time to test our two models against eachother! \n",
    "\n",
    "We will be using the [Google ViT](https://huggingface.co/google/vit-base-patch16-224) from the [Hugging Face](https://huggingface.co/) [`transformers` library](https://huggingface.co/docs/transformers/en/index). We will be using this library often so feel free to get familiar!\n",
    "\n",
    "The AlexNet model in the [FiftyOne Model Zoo](https://docs.voxel51.com/model_zoo/models.html) comes from [pytorch models](https://pytorch.org/vision/main/models.html) and is based off the original paper.\n",
    "\n",
    "We use [FiftyOne's Hugging Face integration](https://docs.voxel51.com/integrations/huggingface.html) to take any `transformers` model and apply it instantly to our dataset. We can do the same with any model from the FiftyOne Model Zoo. After inference is done, check back in your app and compare performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTForImageClassification\n",
    "\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    \"google/vit-base-patch16-224\"\n",
    ")\n",
    "dataset.apply_model(model, label_field=\"ViT_predictions\")\n",
    "\n",
    "model = foz.load_zoo_model(\"alexnet-imagenet-torch\")\n",
    "dataset.apply_model(model, label_field=\"AlexNet-predictions\")\n",
    "\n",
    "\n",
    "session.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![compare](./assets/compare.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking Forward\n",
    "\n",
    "In our next chapter, we will learn all about how we can begin using transformers right away, including how to load, inference, and evaluate transformers yourself. Hop over to Chapter 3 to learn more!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
