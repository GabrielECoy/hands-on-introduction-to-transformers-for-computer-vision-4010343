{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision Transformer for Classification Example\n",
    "## Chapter 3 Module 3\n",
    "\n",
    "Now that we are aquainted with Transformers and FiftyOne, we can make our first go at using a Transformer on a dataset. We are going to jump right in with a sample of [Imagenet](https://www.image-net.org/) and the [ViT](https://huggingface.co/google/vit-base-patch16-224).\n",
    "\n",
    "## Loading a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz \n",
    "\n",
    "dataset = foz.load_zoo_dataset(\n",
    "    \"imagenet-sample\",\n",
    "    dataset_name=\"Imagenet-Sample\",\n",
    "    max_samples=50,\n",
    "    shuffle=True,\n",
    "    overwrite=True,\n",
    ")\n",
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Inference with the Help of FiftyOne\n",
    "\n",
    "You can remember from last chapter ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTForImageClassification\n",
    "\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    \"google/vit-base-patch16-224\"\n",
    ")\n",
    "dataset.apply_model(model, label_field=\"ViT_predictions\")\n",
    "\n",
    "\n",
    "\n",
    "session.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Inference Manually\n",
    "\n",
    "We will show how to leverage FiftyOne dataset to help store all of our model predictions and allow us to visualize our results.\n",
    "\n",
    "But this time we will do it ourselves!\n",
    "\n",
    "Remember the pipeline almost always looks like:\n",
    "\n",
    "1. Load your image\n",
    "2. Preprocess your image\n",
    "3. Inference on your image\n",
    "4. Decode the prediction\n",
    "\n",
    "Let's first start with just a single image from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab just the first image\n",
    "sample = dataset.first()\n",
    "print(sample)\n",
    "\n",
    "# Get the image file path\n",
    "filepath = sample.filepath\n",
    "print(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTForImageClassification\n",
    "from transformers import ViTImageProcessor\n",
    "from PIL import Image\n",
    "\n",
    "# Load the matching processor\n",
    "processor = ViTImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "\n",
    "# Load a pretrained ViT model\n",
    "model = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "\n",
    "# 1. Load our image for inference\n",
    "image = Image.open(filepath)\n",
    "\n",
    "# 2. Preprocess\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "# 3. Run inference\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# 4. Decode prediction\n",
    "predicted_class_idx = outputs.logits.argmax(-1).item()\n",
    "predicted_label = model.config.id2label[predicted_class_idx]\n",
    "\n",
    "print(f\"Predicted class: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have that label, let's add it to our FiftyOne dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[\"Manual_ViT_Predictions\"] = fo.Classification(label=predicted_label)\n",
    "sample.save()\n",
    "print(sample.field_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that it is saved to our dataset, we can view on our app to compare it to the ground truths!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets predict an entire dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in dataset:\n",
    "    # 1. Load our image for inference\n",
    "    image = Image.open(sample.filepath)\n",
    "\n",
    "    # 2. Preprocess\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "    # 3. Run inference\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # 4. Decode prediction\n",
    "    predicted_class_idx = outputs.logits.argmax(-1).item()\n",
    "    predicted_label = model.config.id2label[predicted_class_idx]\n",
    "\n",
    "    # 5. Save the prediction to the sample\n",
    "    sample[\"Manual_ViT_Predictions\"] = fo.Classification(label=predicted_label)\n",
    "    sample.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta da! We have now inferenced over an entire dataset! We can load images and inference in many ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# Load from a file\n",
    "image = Image.open(\"path/to/your/image.jpg\").convert(\"RGB\")\n",
    "\n",
    "# Load from a URL\n",
    "url = \"https://upload.wikimedia.org/wikipedia/commons/3/3a/Cat03.jpg\"\n",
    "response = requests.get(url)\n",
    "image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "\n",
    "# Open the default webcam (camera 0)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "ret, frame = cap.read()\n",
    "cap.release()\n",
    "\n",
    "if ret:\n",
    "    # OpenCV loads in BGR â€” convert to RGB\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    image = Image.fromarray(frame_rgb)\n",
    "\n",
    "    # Show the captured image\n",
    "    image.show()\n",
    "else:\n",
    "    print(\"Failed to capture image from camera.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
